{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f1375c-45ac-4105-889b-97f353c069a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### So we first calculate the metavalues of our dataset using the Automated Imbalanced Classification model, the complete code for which we took from a research paper, which we we have cited in the documentation \n",
    "This is CPU intensive task and for this we used Google Collab to get the values, So the jury doesn't need to run this code, because we have already prepared the values into our final metavalue table, which we will be showing further.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2754757-c4ad-46ca-9cc3-bbec8d9ae735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So first of all we are calculating the value of all the metafeatures for our dataset -->\n",
    "# All of these paths refers to the google drive \n",
    "!pip install virtualenv\n",
    "!virtualenv myenv\n",
    "!source myenv/bin/activate\n",
    "!pip install -r \"/content/drive/MyDrive/Hackathons@TeamKuleli/GST Prediction Model/AIC/requirements.txt\"\n",
    "!pip install dask[dataframe]\n",
    "!pip uninstall scikit-learn imbalanced-learn -y\n",
    "!pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1\n",
    "!python \"/content/drive/MyDrive/Hackathons@TeamKuleli/GST Prediction Model/AIC/project/ml.py\"\n",
    "!python \"/content/drive/MyDrive/Hackathons@TeamKuleli/GST Prediction Model/AIC/project/_test_pymfe.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e44154-d1eb-401f-b566-2b2d497c1fc2",
   "metadata": {},
   "source": [
    "### Writing the generated metavalues to the main table..\n",
    "So we got the metavalues via the previous code run, and now we need to write these metavalues into a record that has to be created in the main metavalues table that contains the metavalues for all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135fb99-682b-4be7-8787-8582a07f0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Below are all the metavalues generated for our training dataset. \n",
    "data = {\n",
    "    'dataset': ['gst_pred'],  \n",
    "    'attr_to_inst': [0.00088],\n",
    "    'best_node.kurtosis': [-0.8880538388594736],\n",
    "    'best_node.mean': [0.9621600000000001],\n",
    "    'best_node.sd': [0.0025452351997845165],\n",
    "    'best_node.skewness': [0.5535286455546834],\n",
    "    'c1': [0.45059680760552145],\n",
    "    'c2': [0.7940436903267976],\n",
    "    'can_cor.kurtosis': [float('nan')],\n",
    "    'can_cor.mean': [0.7500350420232564],\n",
    "    'can_cor.sd': [float('nan')],\n",
    "    'can_cor.skewness': [float('nan')],\n",
    "    'cat_to_num': [0.0],\n",
    "    'cls_coef': [0.9872756911981951],\n",
    "    'cohesiveness.kurtosis': [-1.1527721769300923],\n",
    "    'cohesiveness.mean': [6541.952785],\n",
    "    'cohesiveness.sd': [1093.2308395000773],\n",
    "    'cohesiveness.skewness': [-0.0032894619028259802],\n",
    "    'conceptvar.kurtosis': [5.6729027427966745],\n",
    "    'conceptvar.mean': [0.16699972215095948],\n",
    "    'conceptvar.sd': [0.23464468503045754],\n",
    "    'conceptvar.skewness': [2.7638562563087006],\n",
    "    'cor.kurtosis': [16.198542745898774],\n",
    "    'cor.mean': [0.07605704969574559],\n",
    "    'cor.sd': [0.14825503263024697],\n",
    "    'cor.skewness': [3.863111187644505],\n",
    "    'cov.kurtosis': [224.024418544657],\n",
    "    'cov.mean': [1992.1053870298565],\n",
    "    'cov.sd': [30050.405194344465],\n",
    "    'cov.skewness': [15.00179336914641],\n",
    "    'density': [0.9331630257210288],\n",
    "    'eigenvalues.kurtosis': [14.286344807378292],\n",
    "    'eigenvalues.mean': [245966.25553032718],\n",
    "    'eigenvalues.sd': [994840.954453272],\n",
    "    'eigenvalues.skewness': [3.9062746398041286],\n",
    "    'elite_nn.kurtosis': [3.290119972974221],\n",
    "    'elite_nn.mean': [0.95536],\n",
    "    'elite_nn.sd': [0.01726262500960446],\n",
    "    'elite_nn.skewness': [-2.1744508172652357],\n",
    "    'f1.kurtosis': [12.48085022228258],\n",
    "    'f1.mean': [0.9578908784166184],\n",
    "    'f1.sd': [0.11303801632558654],\n",
    "    'f1.skewness': [-3.600847131107504],\n",
    "    'f1v.kurtosis': [float('nan')],\n",
    "    'f1v.mean': [0.06227569860111687],\n",
    "    'f1v.sd': [float('nan')],\n",
    "    'f1v.skewness': [float('nan')],\n",
    "    'f2.kurtosis': [float('nan')],\n",
    "    'f2.mean': [5.2699716503619274e-17],\n",
    "    'f2.sd': [float('nan')],\n",
    "    'f2.skewness': [float('nan')],\n",
    "    'f3.kurtosis': [float('nan')],\n",
    "    'f3.mean': [0.13208],\n",
    "    'f3.sd': [float('nan')],\n",
    "    'f3.skewness': [float('nan')],\n",
    "    'f4.kurtosis': [float('nan')],\n",
    "    'f4.mean': [0.1262],\n",
    "    'f4.sd': [float('nan')],\n",
    "    'f4.skewness': [float('nan')],\n",
    "    'freq_class.kurtosis': [-2.75],\n",
    "    'freq_class.mean': [0.5],\n",
    "    'freq_class.sd': [0.573774726526012],\n",
    "    'freq_class.skewness': [0.0],\n",
    "    'g_mean.kurtosis': [float('nan')],\n",
    "    'g_mean.mean': [float('nan')],\n",
    "    'g_mean.sd': [float('nan')],\n",
    "    'g_mean.skewness': [float('nan')],\n",
    "    'gravity': [1459.491126553645],\n",
    "    'h_mean.kurtosis': [float('nan')],\n",
    "    'h_mean.mean': [float('nan')],\n",
    "    'h_mean.sd': [float('nan')],\n",
    "    'h_mean.skewness': [float('nan')],\n",
    "    'hubs.kurtosis': [0.012162230622908776],\n",
    "    'hubs.mean': [0.9966315025079404],\n",
    "    'hubs.sd': [0.005352977752692572],\n",
    "    'hubs.skewness': [-1.222371624414329],\n",
    "    'impconceptvar.kurtosis': [6.886573071484975],\n",
    "    'impconceptvar.mean': [1097.061635],\n",
    "    'impconceptvar.sd': [1562.164126279686],\n",
    "    'impconceptvar.skewness': [2.901718866260935],\n",
    "    'inst_to_attr': [1136.3636363636363],\n",
    "    'iq_range.kurtosis': [7.838234195754341],\n",
    "    'iq_range.mean': [238.29259834563635],\n",
    "    'iq_range.sd': [799.5102268380308],\n",
    "    'iq_range.skewness': [2.985507665468452],\n",
    "    'kurtosis.kurtosis': [1.2004198108460367],\n",
    "    'kurtosis.mean': [2865.1675731062805],\n",
    "    'kurtosis.sd': [5691.837569820504],\n",
    "    'kurtosis.skewness': [1.6980151781507031],\n",
    "    'l1.kurtosis': [float('nan')],\n",
    "    'l1.mean': [0.03312360543418835],\n",
    "    'l1.sd': [float('nan')],\n",
    "    'l1.skewness': [float('nan')],\n",
    "    'l2.kurtosis': [float('nan')],\n",
    "    'l2.mean': [0.03295999999999999],\n",
    "    'l2.sd': [float('nan')],\n",
    "    'l2.skewness': [float('nan')],\n",
    "    'l3.kurtosis': [float('nan')],\n",
    "    'l3.mean': [0.01632],\n",
    "    'l3.sd': [float('nan')],\n",
    "    'l3.skewness': [float('nan')],\n",
    "    'leaves': [632],\n",
    "    'leaves_branch.kurtosis': [0.5440531346562016],\n",
    "    'leaves_branch.mean': [16.14240506329114],\n",
    "    'leaves_branch.sd': [6.157106306811797],\n",
    "    'leaves_branch.skewness': [0.8552861035573761],\n",
    "    'leaves_corrob.kurtosis': [624.7167014319785],\n",
    "    'leaves_corrob.mean': [0.0015822784810126586],\n",
    "    'leaves_corrob.sd': [0.03451810793577636],\n",
    "    'leaves_corrob.skewness': [25.011654742004794],\n",
    "    'leaves_homo.kurtosis': [64.9651690022545],\n",
    "    'leaves_homo.mean': [10272686505.014076],\n",
    "    'leaves_homo.sd': [67250297353.66977],\n",
    "    'leaves_homo.skewness': [7.9052742808362355],\n",
    "    'leaves_per_class.kurtosis': [-2.75],\n",
    "    'leaves_per_class.mean': [0.5],\n",
    "    'leaves_per_class.sd': [0.024614476560291185],\n",
    "    'leaves_per_class.skewness': [0.0],\n",
    "    'lh_trace': [1.2859889401679383],\n",
    "    'linear_discr.kurtosis': [0.6533568884618006],\n",
    "    'linear_discr.mean': [0.96424],\n",
    "    'linear_discr.sd': [0.00257302243372352],\n",
    "    'linear_discr.skewness': [1.090872710726285],\n",
    "    'lsc': [0.9884392384],\n",
    "    'mad.kurtosis': [8.738037470786189],\n",
    "    'mad.mean': [168.80729034198941],\n",
    "    'mad.sd': [575.7205926770907],\n",
    "    'mad.skewness': [3.1057456727124317],\n",
    "    'max.kurtosis': [13.184792952862715],\n",
    "    'max.mean': [585.7146572114544],\n",
    "    'max.sd': [2164.841955057148],\n",
    "    'max.skewness': [3.7351066752603685],\n",
    "    'mean.kurtosis': [9.82898507526451],\n",
    "    'mean.mean': [194.41515633254502],\n",
    "    'mean.sd': [677.0033681657069],\n",
    "    'mean.skewness': [3.2541929760102595],\n",
    "    'median.kurtosis': [10.064683511977007],\n",
    "    'median.mean': [176.3178878809091],\n",
    "    'median.sd': [617.2074280197169],\n",
    "    'median.skewness': [3.2866898807295026],\n",
    "    'min.kurtosis': [14.800450391967232],\n",
    "    'min.mean': [-5.239630047318182],\n",
    "    'min.sd': [21.52749376180385],\n",
    "    'min.skewness': [-3.989016465715895],\n",
    "    'n1': [0.06908],\n",
    "    'n2.kurtosis': [1.970082759478621],\n",
    "    'n2.mean': [0.1725220157546187],\n",
    "    'n2.sd': [0.16018590099962085],\n",
    "    'n2.skewness': [1.3452568256377377],\n",
    "    'n3.kurtosis': [18.73900254246719],\n",
    "    'n3.mean': [0.0422],\n",
    "    'n3.sd': [0.20104919007813296],\n",
    "    'n3.skewness': [4.5539272038061345],\n",
    "    'n4.kurtosis': [15.228248473088101],\n",
    "    'n4.mean': [0.04956],\n",
    "    'n4.sd': [0.21703845426012666],\n",
    "    'n4.skewness': [4.150619151204943],\n",
    "    'naive_bayes.kurtosis': [-1.126523053665852],\n",
    "    'naive_bayes.mean': [0.95688],\n",
    "    'naive_bayes.sd': [0.002839718295887807],\n",
    "    'naive_bayes.skewness': [0.6706902692881911],\n",
    "    'nodes': [631],\n",
    "    'nodes_per_attr': [28.681818181818183],\n",
    "    'nodes_per_inst': [0.02524],\n",
    "    'nodes_per_level.kurtosis': [-1.0122162902440375],\n",
    "    'nodes_per_level.mean': [18.02857142857143],\n",
    "    'nodes_per_level.sd': [15.906871830393662],\n",
    "    'nodes_per_level.skewness': [0.664447834657902],\n",
    "    'nodes_repeated.kurtosis': [6.291875618457812],\n",
    "    'nodes_repeated.mean': [31.55],\n",
    "    'nodes_repeated.sd': [58.20424564004172],\n",
    "    'nodes_repeated.skewness': [2.6539697013107535],\n",
    "    'nr_attr': [22],\n",
    "    'nr_bin': [8],\n",
    "    'nr_cat': [0],\n",
    "    'nr_class': [2],\n",
    "    'nr_cor_attr': [0.030303030303030304],\n",
    "    'nr_disc': [1],\n",
    "    'nr_inst': [25000],\n",
    "    'nr_norm': [0.0],\n",
    "    'nr_num': [22],\n",
    "    'nr_outliers': [17],\n",
    "    'num_to_cat': [float('nan')],\n",
    "    'one_itemset.kurtosis': [3.5448627069571215],\n",
    "    'one_itemset.mean': [0.1437908496732026],\n",
    "    'one_itemset.sd': [0.26541289269825896],\n",
    "    'one_itemset.skewness': [2.2462550219971176],\n",
    "    'one_nn.kurtosis': [-1.3098213090731103],\n",
    "    'one_nn.mean': [0.88856],\n",
    "    'one_nn.sd': [0.005511039426057068],\n",
    "    'one_nn.skewness': [-0.4448722906473241],\n",
    "    'p_trace': [0.5625525642628281],\n",
    "    'random_node.kurtosis': [-1.5728571428569713],\n",
    "    'random_node.mean': [0.90572],\n",
    "    'random_node.sd': [0.0001932183566158915],\n",
    "    'random_node.skewness': [0.7452708040898978],\n",
    "    'range.kurtosis': [13.030585591834228],\n",
    "    'range.mean': [590.9542872587728],\n",
    "    'range.sd': [2168.565628277321],\n",
    "    'range.skewness': [3.711878661548337],\n",
    "    'roy_root': [1.2859889401679383],\n",
    "    'sd.kurtosis': [10.244067398490152],\n",
    "    'sd.mean': [139.21508450815006],\n",
    "    'sd.sd': [487.2116557301575],\n",
    "    'sd.skewness': [3.311527953238473],\n",
    "    'sd_ratio': [float('nan')],\n",
    "    'skewness.kurtosis': [2.186332677644123],\n",
    "    'skewness.mean': [16.530067800326638],\n",
    "    'skewness.sd': [48.318667590800594],\n",
    "    'skewness.skewness': [-0.16597152023129574],\n",
    "    'sparsity.kurtosis': [-1.7958320441442654],\n",
    "    'sparsity.mean': [0.19241286772852995],\n",
    "    'sparsity.sd': [0.23927393289604318],\n",
    "    'sparsity.skewness': [0.5001954308625849],\n",
    "    't1.kurtosis': [2100.097446844831],\n",
    "    't1.mean': [0.0004697040864255519],\n",
    "    't1.sd': [0.01647676246910011],\n",
    "    't1.skewness': [45.730050759373526],\n",
    "    't2': [0.00088],\n",
    "    't3': [8e-05],\n",
    "    't4': [0.09090909090909091],\n",
    "    't_mean.kurtosis': [9.298531606422069],\n",
    "    't_mean.mean': [185.78661420330462],\n",
    "    't_mean.sd': [640.3380707146282],\n",
    "    't_mean.skewness': [3.181623853075808],\n",
    "    'tree_depth.kurtosis': [0.49837958900896995],\n",
    "    'tree_depth.mean': [15.155977830562154],\n",
    "    'tree_depth.sd': [6.299087573059601],\n",
    "    'tree_depth.skewness': [0.7851968130374001],\n",
    "    'tree_imbalance.kurtosis': [16.541110455547404],\n",
    "    'tree_imbalance.mean': [0.025122444385825733],\n",
    "    'tree_imbalance.sd': [0.06529051609204348],\n",
    "    'tree_imbalance.skewness': [3.9245540704739046],\n",
    "    'tree_shape.kurtosis': [205.4152070689024],\n",
    "    'tree_shape.mean': [0.00655802246689711],\n",
    "    'tree_shape.sd': [0.02638290949978468],\n",
    "    'tree_shape.skewness': [12.443290277492322],\n",
    "    'two_itemset.kurtosis': [-0.11605865547657368],\n",
    "    'two_itemset.mean': [0.26046203370573756],\n",
    "    'two_itemset.sd': [0.3105296844877253],\n",
    "    'two_itemset.skewness': [1.2311435752961646],\n",
    "    'var.kurtosis': [14.123464153083514],\n",
    "    'var.mean': [245966.2555303273],\n",
    "    'var.sd': [984804.8689045373],\n",
    "    'var.skewness': [3.8804031612292764],\n",
    "    'var_importance.kurtosis': [13.95510601929379],\n",
    "    'var_importance.mean': [0.045454545454545456],\n",
    "    'var_importance.sd': [0.14672595631160387],\n",
    "    'var_importance.skewness': [3.844276185939259],\n",
    "    'w_lambda': [0.43744743573717193],\n",
    "    'wg_dist.kurtosis': [-0.2539868805848031],\n",
    "    'wg_dist.mean': [1.3087498925476844],\n",
    "    'wg_dist.sd': [0.2321179089553534],\n",
    "    'wg_dist.skewness': [0.42160371185858],\n",
    "    'worst_node.kurtosis': [-1.2973659655773535],\n",
    "    'worst_node.mean': [0.90628],\n",
    "    'worst_node.sd': [0.0008011103405759916],\n",
    "    'worst_node.skewness': [0.6692096908131522]\n",
    "}\n",
    "\n",
    "# Creating DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Saving to CSV file\n",
    "df.to_csv('AIC_1/kb_charc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d400bf7-0449-4dfa-851a-a7fdec62fc32",
   "metadata": {},
   "source": [
    "### Then preprocessing the main metavalue dataset..\n",
    "The main metavalue data that has been provided in the repo which now also contains our dataset record, needs to preprocessed to fill all the missing values and perform other preprocessing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6480297-8cdc-42af-a781-03c075a2318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = 'kb_charc.csv'  # Update with your actual file path\n",
    "output_file = 'kb_charc_preprocessed.csv'  # Output file for the preprocessed data\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Display initial summary of data\n",
    "print(\"Initial Data Overview:\")\n",
    "print(df.info())\n",
    "\n",
    "# Drop non-numeric columns if required\n",
    "# Keep 'dataset' column for identification but not for numerical processing\n",
    "non_numeric_columns = ['dataset']\n",
    "numeric_df = df.drop(columns=non_numeric_columns, errors='ignore')\n",
    "\n",
    "# Convert all values to numeric, coercing errors to NaN\n",
    "numeric_df = numeric_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "numeric_df = numeric_df.fillna(0)\n",
    "\n",
    "# Replace infinite values with NaN and re-fill with 0\n",
    "numeric_df = numeric_df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Normalize values between 0 and 1\n",
    "numeric_df = (numeric_df - numeric_df.min()) / (numeric_df.max() - numeric_df.min() + 1e-10)\n",
    "\n",
    "# Reattach non-numeric columns, if any, like 'dataset'\n",
    "preprocessed_df = pd.concat([df[non_numeric_columns], numeric_df], axis=1)\n",
    "\n",
    "# Save the preprocessed data to a new CSV file\n",
    "preprocessed_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display final summary of processed data\n",
    "print(\"Preprocessing Complete. Processed Data Overview:\")\n",
    "print(preprocessed_df.info())\n",
    "print(f\"Preprocessed data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6506d-44a3-43ff-a94c-4b711c5db11f",
   "metadata": {},
   "source": [
    "### Getting the top 3 matches for the most nearest combinations..\n",
    "So we get the top 3 match matches which have the least euclidean distance value from our record characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b6b76-7d21-4f75-b345-7a0a6275bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed CSV file containing the meta-features\n",
    "file_path = 'kb_charc_preprocessed.csv'  # Update with your actual preprocessed file path\n",
    "df_characteristics = pd.read_csv(file_path)\n",
    "\n",
    "# Set your current dataset name\n",
    "current_dataset_name = \"gst_pred\"  # Replace with your actual dataset name\n",
    "df_current = df_characteristics[df_characteristics['dataset'] == current_dataset_name]\n",
    "\n",
    "if df_current.empty:\n",
    "    print(\"The current dataset is not found in the characteristics file.\")\n",
    "    exit()\n",
    "\n",
    "# Extract meta-features of the current dataset and drop the 'dataset' column\n",
    "meta_features_current = df_current.drop(columns=['dataset'])\n",
    "\n",
    "# Initialize an empty list to store distances\n",
    "distances = []\n",
    "\n",
    "# Iterate over each dataset in the characteristics file\n",
    "for index, row in df_characteristics.iterrows():\n",
    "    # Skip the current dataset itself\n",
    "    if row['dataset'] == current_dataset_name:\n",
    "        continue\n",
    "\n",
    "    # Extract meta-features of the other dataset\n",
    "    meta_features_other = row.drop(labels=['dataset'])\n",
    "\n",
    "    # Ensure both datasets have the same number of features before distance calculation\n",
    "    if len(meta_features_current.columns) != len(meta_features_other):\n",
    "        print(f\"Skipping dataset {row['dataset']} due to column mismatch.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate the Euclidean distance between the meta-features\n",
    "    distance = np.linalg.norm(meta_features_current.values[0] - meta_features_other.values)\n",
    "    \n",
    "    # Append the dataset name and the calculated distance\n",
    "    distances.append((row['dataset'], distance))\n",
    "\n",
    "# Sort the distances and get the top three closest datasets\n",
    "distances.sort(key=lambda x: x[1])\n",
    "top_three_datasets = distances[:3]\n",
    "\n",
    "# Display the top three similar datasets\n",
    "if top_three_datasets:\n",
    "    print(\"Top three datasets most similar to your dataset:\")\n",
    "    for dataset, distance in top_three_datasets:\n",
    "        print(f\"Dataset: {dataset}, Distance: {distance:.4f}\")\n",
    "else:\n",
    "    print(\"No valid comparisons could be made; check data for consistency.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
